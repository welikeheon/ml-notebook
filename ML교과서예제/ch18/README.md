머신 러닝 교과서 2판


##  18장 - 강화 학습으로 복잡한 환경에서 의사 결정하기


### 목차

- 경험에서 배웁니다
    - 강화 학습 이해하기
    - 강화 학습 시스템의 에이전트-환경 인터페이스 정의하기
- 강화 학습의 기초 이론
    - 마르코프 결정 과정
    - 마르코프 결정 과정의 수학 공식
        - 마르코프 과정 시각화
        - 에피소드 작업 대 연속적인 작업
    - 강화 학습 용어: 대가, 정책, 가치 함수
        - 대가
        - 정책
        - 가치 함수
    - 벨먼 방정식을 사용한 동적 계획법
- 강화 학습 알고리즘
    - 동적 계획법
        - 정책 평가 - 동적 계획법으로 가치 함수 예측하기
        - 추정된 가치 함수로 정책 향상시키기
        - 정책 반복
        - 가치 반복
    - 몬테 카를로를 사용한 강화 학습
        - MC를 사용한 상태-가치 함수 추정
        - MC를 사용한 행동-가치 함수 추정
        - MC 제어를 사용해 최적의 정책 찾기
        - 정책 향상 - 행동-가치 함수로부터 그리디 정책 계산하기
    - 시간차 학습
        - TD 예측
        - 온-폴리시 TD 제어 (SARSA)
        - 오프-폴리시 TD 제어 (Q-러닝)
- 첫 번째 강화 학습 알고리즘 구현하기
    - OpenAI 짐 툴킷 소개
        - OpenAI 짐에 포함된 환경 사용하기
        - 그리드 월드
        - OpenAI 짐에서 그리드 월드 환경 구현하기
    - Q-러닝으로 그리드 월드 문제 풀기
        - Q-러닝 알고리즘 구현하기
    - 심층 Q-러닝
        - Q-러닝 알고리즘에 따라 DQN 모델 훈련하기
            - 재생 메모리
            - 손실 계산을 위해 타깃 가치 결정하기
    - 심층 Q-러닝 알고리즘 구현
- 전체 요약

### 코드 사용 방법 안내

이 책의 코드를 사용하는 가장 좋은 방법은 주피터 노트북(`.ipynb` 파일)입니다. 주피터 노트북을 사용하면 단계적으로 코드를 실행하고 하나의 문서에 편리하게 (그림과 이미지를 포함해) 모든 출력을 저장할 수 있습니다.

![](../ch02/images/jupyter-example-1.png)

주피터 노트북은 매우 간단하게 설치할 수 있습니다. 아나콘다 파이썬 배포판을 사용한다면 터미널에서 다음 명령을 실행하여 주피터 노트북을 설치할 수 있습니다:

    conda install jupyter notebook

다음 명령으로 주피터 노트북을 실행합니다.

    jupyter notebook

브라우저에서 윈도우가 열리면 원하는 `.ipynb`가 들어 있는 디렉토리로 이동할 수 있습니다.

**설치와 설정에 관한 더 자세한 내용은 1장의 [README.md 파일](../ch01/README.md)에 있습니다.**

**(주피터 노트북을 설치하지 않았더라도 깃허브에서 [`ch18.ipynb`](https://github.com/rickiepark/python-machine-learning-book-3rd-edition/blob/master/ch18/ch18.ipynb)을 클릭해 노트북 파일을 볼 수 있습니다.)**.

코드 예제 외에도 주피터 노트북에는 책의 내용에 맞는 섹션 제목을 함께 실었습니다. 또한 주피터 노트북에 원본 이미지와 그림을 포함시켰기 때문에 책을 읽으면서 코드를 쉽게 따라할 수 있으면 좋겠습니다.

![](../ch02/images/jupyter-example-2.png)