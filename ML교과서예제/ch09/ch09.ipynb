{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PLo5qcAawlk"
   },
   "source": [
    "# 머신 러닝 교과서 3판"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlmrX27Yawlo"
   },
   "source": [
    "# 9장 - 웹 애플리케이션에 머신 러닝 모델 내장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NSuaIVEawlp"
   },
   "source": [
    "**아래 링크를 통해 이 노트북을 주피터 노트북 뷰어(nbviewer.jupyter.org)로 보거나 구글 코랩(colab.research.google.com)에서 실행할 수 있습니다.**\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/rickiepark/python-machine-learning-book-3rd-edition/blob/master/ch09/ch09.ipynb\"><img src=\"https://jupyter.org/assets/main-logo.svg\" width=\"28\" />주피터 노트북 뷰어로 보기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/python-machine-learning-book-3rd-edition/blob/master/ch09/ch09.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTRiUUjbawlp"
   },
   "source": [
    "### 목차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D29IAkPMawlp"
   },
   "source": [
    "- 8장 정리 - 영화 리뷰 분류를 위한 모델 훈련하기\n",
    "- 학습된 사이킷런 추정기 저장\n",
    "- 데이터를 저장하기 위해 SQLite 데이터베이스 설정\n",
    "- 플라스크 웹 애플리케이션 개발\n",
    "    - 첫 번째 플라스크 애플리케이션\n",
    "    - 폼 검증과 화면 출력\n",
    "- 영화 리뷰 분류기를 웹 애플리케이션으로 만들기\n",
    "- 공개 서버에 웹 애플리케이션 배포\n",
    "    - 영화 분류기 업데이트\n",
    "- 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EaewSNJawlq",
    "outputId": "2fa63058-a270-4263-c43b-b2456b58ea35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/4c/6111b9a325f29527d7f262e2ee8c730d354b47a728d955e186dacad57a0d/scikit_learn-0.24.1-cp36-cp36m-manylinux2010_x86_64.whl (22.2MB)\n",
      "\u001b[K     |████████████████████████████████| 22.2MB 3.8MB/s \n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.5)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "  Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "# 코랩에서 실행할 경우 최신 버전의 사이킷런을 설치합니다.\n",
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DXLkk_PSawlq"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rq-n6UClawlq"
   },
   "source": [
    "플래스크(Flask) 웹 애플리케이션 코드는 다음 디렉토리에 있습니다:\n",
    "    \n",
    "- `1st_flask_app_1/`: 간단한 플래스크 웹 애플리케이션\n",
    "- `1st_flask_app_2/`: `1st_flask_app_1`에 폼 검증과 렌더링을 추가하여 확장한 버전\n",
    "- `movieclassifier/`: 웹 애플리케이션에 내장한 영화 리뷰 분류기\n",
    "- `movieclassifier_with_update/`: `movieclassifier`와 같지만 초기화를 위해 sqlite 데이터베이스를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7BU7MFwawlq"
   },
   "source": [
    "웹 애플리케이션을 로컬에서 실행하려면 `cd`로 (위에 나열된) 각 디렉토리에 들어가서 메인 애플리케이션 스크립트를 실행합니다.\n",
    "\n",
    "    cd ./1st_flask_app_1\n",
    "    python app.py\n",
    "    \n",
    "터미널에서 다음같은 내용일 출력됩니다.\n",
    "    \n",
    "     * Running on http://127.0.0.1:5000/\n",
    "     * Restarting with reloader\n",
    "     \n",
    "웹 브라우저를 열고 터미널에 출력된 주소(일반적으로 http://127.0.0.1:5000/)를 입력하여 웹 애플리케이션에 접속합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtmgp48bawlr"
   },
   "source": [
    "**이 튜토리얼로 만든 예제 애플리케이션 데모는 다음 주소에서 볼 수 있습니다: http://haesun.pythonanywhere.com/**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3cBNe2Nawlr"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxZ6m_xNawlr"
   },
   "source": [
    "# 8장 정리 - 영화 리뷰 분류를 위한 모델 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MFI3KC4awlr"
   },
   "source": [
    "이 절은 8장의 마지막 섹션에서 훈련한 로지스틱 회귀 모델을 다시 사용합니다. 이어지는 코드 블럭을 실행하여 다음 절에서 사용할 모델을 훈련시키겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJKe25Wzawlr"
   },
   "source": [
    "**노트**\n",
    "\n",
    "다음 코드는 8장에서 만든 `movie_data.csv` 데이터셋을 사용합니다.\n",
    "\n",
    "**코랩을 사용할 때는 다음 셀을 실행하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgIZKmUhawlr",
    "outputId": "7d05c12d-faca-45b1-b2b4-e0bde176f82e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-23 08:45:33--  https://github.com/rickiepark/python-machine-learning-book-2nd-edition/raw/master/code/ch09/movie_data.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.113.3\n",
      "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-2nd-edition/master/code/ch09/movie_data.csv.gz [following]\n",
      "--2021-01-23 08:45:33--  https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-2nd-edition/master/code/ch09/movie_data.csv.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26521894 (25M) [application/octet-stream]\n",
      "Saving to: ‘movie_data.csv.gz’\n",
      "\n",
      "movie_data.csv.gz   100%[===================>]  25.29M  81.9MB/s    in 0.3s    \n",
      "\n",
      "2021-01-23 08:45:34 (81.9 MB/s) - ‘movie_data.csv.gz’ saved [26521894/26521894]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/rickiepark/python-machine-learning-book-3rd-edition/raw/master/ch09/movie_data.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1M6joYaSawls"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "\n",
    "with gzip.open('movie_data.csv.gz') as f_in, open('movie_data.csv', 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BX9nOi6iawls",
    "outputId": "1049abf7-ec82-4e1b-f066-27bcb1109c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pY02dzhLawls"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "def stream_docs(path):\n",
    "    with open(path, 'r', encoding='utf-8') as csv:\n",
    "        next(csv) # skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QdRlmGbYawlt",
    "outputId": "a7090cc4-fe2b-480f-b173-95a8db5b4244"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"\"Murder in Greenwich\"\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available\"',\n",
       " 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(stream_docs(path='movie_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5rS-FN4qawlt"
   },
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YtYRd4hOawlt"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore', \n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None, \n",
    "                         tokenizer=tokenizer)\n",
    "\n",
    "clf = SGDClassifier(loss='log', random_state=1, max_iter=1)\n",
    "doc_stream = stream_docs(path='movie_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjosjLbrawlt"
   },
   "source": [
    "`pyprind`는 주피터 노트북에서 진행바를 출력하기 위한 유틸리티입니다. `pyprind` 패키지를 설치하려면 다음 셀을 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_cxkFqsawlt",
    "outputId": "1f45d752-2062-499a-f3cc-c3f0c5a7eff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyprind\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/30/e76fb0c45da8aef49ea8d2a90d4e7a6877b45894c25f12fb961f009a891e/PyPrind-2.11.2-py3-none-any.whl\n",
      "Installing collected packages: pyprind\n",
      "Successfully installed pyprind-2.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyprind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tPgFFoRZawlt",
    "outputId": "c51f65ac-864a-46e4-ca0f-f812cd13b998"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:27\n"
     ]
    }
   ],
   "source": [
    "import pyprind\n",
    "pbar = pyprind.ProgBar(45)\n",
    "\n",
    "classes = np.array([0, 1])\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7atznfEawlu",
    "outputId": "ca6d717d-51fc-410c-ac8c-3f1ab7db35ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.868\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
    "X_test = vect.transform(X_test)\n",
    "print('정확도: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "F-YXSL6lawlu"
   },
   "outputs": [],
   "source": [
    "clf = clf.partial_fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1V1obTq2awlu"
   },
   "source": [
    "### 노트\n",
    "\n",
    "pickle 파일을 만드는 것이 조금 까다로울 수 있기 때문에 `pickle-test-scripts/` 디렉토리에 올바르게 환경이 설정되었는지 확인하는 간단한 테스트 스크립트를 추가했습니다. 기본적으로 `movie_data` 데이터 일부를 포함하고 있고 `ch08`의 관련된 코드를 정리한 버전입니다.\n",
    "\n",
    "다음처럼 실행하면\n",
    "\n",
    "    python pickle-dump-test.py\n",
    "\n",
    "`movie_data_small.csv`에서 작은 분류 모델을 훈련하고 2개의 pickle 파일을 만듭니다.\n",
    "\n",
    "    stopwords.pkl\n",
    "    classifier.pkl\n",
    "\n",
    "그다음 아래 명령을 실행하면\n",
    "\n",
    "    python pickle-load-test.py\n",
    "\n",
    "다음 2줄이 출력되어야 합니다:\n",
    "\n",
    "    Prediction: positive\n",
    "    Probability: 85.71%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSLt4q2iawlu"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mVIgR16awlu"
   },
   "source": [
    "# 학습된 사이킷런 추정기 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGgh44F5awlu"
   },
   "source": [
    "앞에서 로지스틱 회귀 모델을 훈련한 후에 분류기, 불용어, 포터 어간 추출기, `HashingVectorizer`를 로컬 디스크에 직렬화된 객체로 저장합니다. 나중에 웹 애플리케이션에서 학습된 분류기를 이용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MCaQNEgzawlv"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "dest = os.path.join('movieclassifier', 'pkl_objects')\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "\n",
    "pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'), 'wb'), protocol=4)   \n",
    "pickle.dump(clf, open(os.path.join(dest, 'classifier.pkl'), 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-go6y-Y0awlv"
   },
   "source": [
    "그다음 나중에 임포트할 수 있도록 별도의 파일에 `HashingVectorizer`를 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rlgFcHlYawlv",
    "outputId": "3b834254-5dcd-4f14-e6f1-3d5208680dde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing movieclassifier/vectorizer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile movieclassifier/vectorizer.py\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "cur_dir = os.path.dirname(__file__)\n",
    "stop = pickle.load(open(\n",
    "                os.path.join(cur_dir, \n",
    "                'pkl_objects', \n",
    "                'stopwords.pkl'), 'rb'))\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) \\\n",
    "                   + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBCFPHclawlv"
   },
   "source": [
    "이전 코드 셀을 실행한 후에 객체가 올바르게 저장되었는지 확인하기 위해 IPython 노트북 커널을 재시작할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgwwuZH3awlv"
   },
   "source": [
    "먼저 현재 파이썬 디렉토리를 `movieclassifer`로 변경합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "x2ss0iwKawlv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('movieclassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "RUjz2v7Gawlv"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import os\n",
    "from vectorizer import vect\n",
    "\n",
    "clf = pickle.load(open(os.path.join('pkl_objects', 'classifier.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6UMp7VH1awlw",
    "outputId": "5d4a6356-1be1-455b-ee21-8f486f22b52c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: 양성\n",
      "확률: 95.55%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "label = {0:'음성', 1:'양성'}\n",
    "\n",
    "example = [\"I love this movie. It's amazing.\"]\n",
    "X = vect.transform(example)\n",
    "print('예측: %s\\n확률: %.2f%%' %\\\n",
    "      (label[clf.predict(X)[0]], \n",
    "       np.max(clf.predict_proba(X))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yy5BKna7awlw"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joixYXoXawlw"
   },
   "source": [
    "# 데이터를 저장하기 위해 SQLite 데이터베이스 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17ckroSPawlw"
   },
   "source": [
    "이 코드를 실행하기 전에 현재 위치가 `movieclassifier` 디렉토리인지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "xlQDh61Gawlw",
    "outputId": "b0edace2-5bc3-4bf5-aa85-42dd56cb31be"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/movieclassifier'"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9cZe4L0tawlx"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "conn = sqlite3.connect('reviews.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('DROP TABLE IF EXISTS review_db')\n",
    "c.execute('CREATE TABLE review_db (review TEXT, sentiment INTEGER, date TEXT)')\n",
    "\n",
    "example1 = 'I love this movie'\n",
    "c.execute(\"INSERT INTO review_db (review, sentiment, date) VALUES (?, ?, DATETIME('now'))\", (example1, 1))\n",
    "\n",
    "example2 = 'I disliked this movie'\n",
    "c.execute(\"INSERT INTO review_db (review, sentiment, date) VALUES (?, ?, DATETIME('now'))\", (example2, 0))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Mbe3UZgfawlx"
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('reviews.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute(\"SELECT * FROM review_db WHERE date BETWEEN '2017-01-01 10:10:10' AND DATETIME('now')\")\n",
    "results = c.fetchall()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwa3g4tQawlx",
    "outputId": "5673fda9-c411-497e-9932-5e85169e5de4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I love this movie', 1, '2021-01-23 08:46:11'), ('I disliked this movie', 0, '2021-01-23 08:46:11')]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "1Wt6k_PLawlx",
    "outputId": "6fe51e9d-ef8b-4d89-fcc6-341e403c79e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://git.io/Jts3V\" width=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://git.io/Jts3V', width=700) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RKw4dd0awlx"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4V6Gx6Tawlx"
   },
   "source": [
    "# 플라스크 웹 애플리케이션 개발"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdv7WCFVawlx"
   },
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0i4Ktl2Oawly"
   },
   "source": [
    "## 첫 번째 플라스크 애플리케이션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbqsOJouawly"
   },
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "sqVxyOD_awly",
    "outputId": "e8f259c3-3b3e-4824-9786-93bfe7b067a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://git.io/Jts3o\" width=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://git.io/Jts3o', width=700) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HL4wMjzUawly"
   },
   "source": [
    "## 폼 검증과 화면 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "fYzE9i3-awly",
    "outputId": "580ae07d-3ce3-44c7-80b4-0f8caf09ae42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://git.io/Jts3K\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://git.io/Jts3K', width=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "aKBsBCFWawly",
    "outputId": "b99978f8-cc7b-4bda-8a39-2b05454694c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://git.io/Jts36\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://git.io/Jts36', width=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UC5SMipWawly"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QugsT1TGawlz"
   },
   "source": [
    "## 화면 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "B-pYhG_Dawlz",
    "outputId": "db14d199-cb0f-4ade-c65a-38125d6dca7a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://git.io/Jts3P\" width=\"800\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://git.io/Jts3P', width=800) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "LGy4kOWOawlz",
    "outputId": "142ccd2d-4c65-44b6-99c6-18f954544699"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://git.io/Jts3X\" width=\"800\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://git.io/Jts3X', width=800) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "VySNEDCBawlz",
    "outputId": "a7ffcc40-daa9-4e25-b607-8b0bf765326b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://git.io/Jts31\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://git.io/Jts31', width=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sboq5JaDawlz"
   },
   "source": [
    "# 영화 리뷰 분류기를 웹 애플리케이션으로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "OXmQFwofawlz",
    "outputId": "b934fb43-41fe-4035-aca1-459dcdc1ec36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://git.io/Jts3M\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://git.io/Jts3M', width=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "5hlCDl4Qawlz",
    "outputId": "9ac93bc1-768a-4a1d-c7d4-e04802a2fa53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://git.io/Jts3D\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://git.io/Jts3D', width=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "id": "H2IWwFo4awl0",
    "outputId": "c2a4ea45-f5ce-4a2a-b0b1-4bafbd3e1fe5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://git.io/Jts3y\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://git.io/Jts3y', width=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "NDdF8d_Dawl0",
    "outputId": "8d8f6010-87df-463c-c751-7e725a79f908"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://git.io/Jts3S\" width=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://git.io/Jts3S', width=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "oDMBlVbjawl0",
    "outputId": "514d82ee-5b30-4ed1-c3f5-05ef1052ea2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://git.io/Jts32\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://git.io/Jts32', width=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYjcDtqpawl0"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDhAf2xQawl0"
   },
   "source": [
    "# 공개 서버에 웹 애플리케이션 배포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "mUUr4cloawl1",
    "outputId": "accb920b-a321-4e97-c408-a8833e495bba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://git.io/Jts39\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://git.io/Jts39', width=600) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tz5xeyR_awl1"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfE3tvN6awl1"
   },
   "source": [
    "## 영화 분류기 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDM3DF_Jawl1"
   },
   "source": [
    "다운로드한 깃허브 저장소에 들어있는 movieclassifier_with_update 디렉토리를 사용합니다(그렇지 않으면 `movieclassifier` 디렉토리를 복사해서 사용하세요)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDF4lqx5awl1"
   },
   "source": [
    "**코랩을 사용할 때는 다음 셀을 실행하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "JC0mvtTBawl2"
   },
   "outputs": [],
   "source": [
    "!cp -r ../movieclassifier ../movieclassifier_with_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yWt0Z10Cawl2",
    "outputId": "bdac1e13-ba6c-4e07-fbe3-90b6abff92ad"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./reviews.sqlite'"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "if not os.path.exists('movieclassifier_with_update'):\n",
    "    os.mkdir('movieclassifier_with_update')\n",
    "os.chdir('movieclassifier_with_update')\n",
    "\n",
    "if not os.path.exists('pkl_objects'):\n",
    "    os.mkdir('pkl_objects')\n",
    "\n",
    "shutil.copyfile('../movieclassifier/pkl_objects/classifier.pkl',\n",
    "                './pkl_objects/classifier.pkl')\n",
    "\n",
    "shutil.copyfile('../movieclassifier/reviews.sqlite',\n",
    "                './reviews.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2yiWBk8awl2"
   },
   "source": [
    "SQLite 데이터베이스에 저장된 데이터로 분류기를 업데이트하는 함수를 정의합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "cEG3QW8wawl2"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "# 로컬 디렉토리에서 HashingVectorizer를 임포트합니다\n",
    "from vectorizer import vect\n",
    "\n",
    "def update_model(db_path, model, batch_size=10000):\n",
    "\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute('SELECT * from review_db')\n",
    "    \n",
    "    results = c.fetchmany(batch_size)\n",
    "    while results:\n",
    "        data = np.array(results)\n",
    "        X = data[:, 0]\n",
    "        y = data[:, 1].astype(int)\n",
    "    \n",
    "        classes = np.array([0, 1])\n",
    "        X_train = vect.transform(X)\n",
    "        clf.partial_fit(X_train, y, classes=classes)\n",
    "        results = c.fetchmany(batch_size)\n",
    "    \n",
    "    conn.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_alTEyGaawl2"
   },
   "source": [
    "모델을 업데이트합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "0qeEwRm5awl2"
   },
   "outputs": [],
   "source": [
    "cur_dir = '.'\n",
    "\n",
    "# app.py 파일에 이 코드를 삽입했다면 다음 경로를 사용하세요.\n",
    "\n",
    "# import os\n",
    "# cur_dir = os.path.dirname(__file__)\n",
    "\n",
    "clf = pickle.load(open(os.path.join(cur_dir,\n",
    "                 'pkl_objects',\n",
    "                 'classifier.pkl'), 'rb'))\n",
    "db = os.path.join(cur_dir, 'reviews.sqlite')\n",
    "\n",
    "update_model(db_path=db, model=clf, batch_size=10000)\n",
    "\n",
    "# classifier.pkl 파일을 업데이트하려면 다음 주석을 해제하세요.\n",
    "\n",
    "# pickle.dump(clf, open(os.path.join(cur_dir, \n",
    "#             'pkl_objects', 'classifier.pkl'), 'wb')\n",
    "#             , protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B3Gxlfhawl2"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ch09.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
